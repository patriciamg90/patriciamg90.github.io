<!DOCTYPE HTML>
<!--
	Spatial by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title> </title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body>

		<!-- Header -->
		    
            </script>
			<header id="header">
				<h1><strong><a href="index.html"> </a></strong>  </h1>
				<nav id="nav">
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="research.html">Research</a></li>
						
						<li><a href="teaching.html">Teaching</a></li>
						<li><a href="service.html">Service</a></li>
						<li><a href="about.html">About</a></li>
						<li><a href="miscellaneous.html">Miscellaneous</a></li>
						
					</ul>
				</nav>
			</header>

			<a href="#menu" class="navPanelToggle"><span class="fa fa-bars"></span></a>

		<!-- Main -->
			<section id="main" class="wrapper">
				<div class="container">

					<header class="major special">
						<h2>Research Interests</h2>
						<p>Numerical analysis, analysis of PDE's and deep learning</p>
						<ul class="actions">
								<li><a href="publications.html" class="button special">Publications</a></li>
								<li><a href="presentations.html" class="button">Presentations</a></li>
								
							</ul>
						
					</header>
					<p> My current research is in applying rigorous mathematical concepts in machine learning. In particular, my current work builds on several projects including deep learning in geospatial data such as 3D point cloud data (LiDAR).  I am interested in both the computational aspects and the mathematical aspects of deep learning. For instance, intrinsic dimension estimation (although the data may be embedded in R^D^, its intrinsic dimension (the minimum number $d$ such that the data set lies entirely within a $d$-dimensional subspace of $\mathbb{R}^D^d$, is often much smaller than $D$), which falls under the general umbrella of \underline{dimensionality reduction}. In the computation side, creating new frameworks involving generating more features by borrowing ideas from different mathematical areas such as measure theory. For example, measures defined on dyadic sets which are sets with an ordered binary tree of subsets.</p>
					
					<p><span class="image left"><img src="images/TreeDiagram02.jpg" alt="" /></span><h4>Deep learning in 3D point cloud LiDAR data</h4>
					I was involved in a project from a Workshop at ICERM ("Women in Data Science and Mathematics", July 17–21, 2017). We proposed a heuristic framework for testing a multi–manifold hypothesis on real–world data sets. Our method partitions a data set into subsets based on intrinsic dimension and constructs a multi–manifold that fits each subset. We tested a manifold hypothesis in a 3D LiDAR point cloud data (Light Detection and Ranging, a remote sensing method used to examine the surface of the Earth) of the Golden Gate Bridge in San Francisco. The goal is to develop a machine learning algorithm to make a classification of the LiDAR 3D point cloud data. For example, identifying vegetation, gravel, sand and other aspects of interest in the Geoscience from a single LiDAR image. My long term project is to incorporate information from LiDAR data of porous surface to my previous studies of models involving methane.

                    In particular, we want to classify LiDAR data using an auto–encoder algorithm (deep learning). An auto–encoder neural network is an unsupervised learning algorithm that applies backpropagation, setting the target values to be equal to the inputs. We use auto–encoders combined with a neural network to classify all the points of a 3D LiDAR point cloud data into elementary, relevant classes, for example, according to their morphology. Features include spatial coordinates (x, y and z) intensity, number of returns, RGB among others. We begin by classifying all the points of the LiDAR data as ground points or non–ground points. Many classification techniques from supervised learning (e.g. convolutional neural networks) have been used to classify 3D point clouds of natural environments with good accurate results. We alsoaim to test the classification accuracy of the aforementioned unsupervised learning framework.</p>
					
					
			<!-- <a		<p><span class="image right"><img src="images/filename.png" alt="" /></span><h5>Title</h5> content  </p> </a> -->
			
			    <p><span class="image right"><img src="images/3layer-autoencoder.jpg" alt="" /></span><h5>Solutions for climate change science: using deep learning to improve vegetation classification</h5>Over the last decade, the Remote Sensing and Geospatial Laboratory (RSGL) from University of UW has
                collected and analyzed LiDAR 3D Point cloud data from different sites in Oregon and Washington through both direct–based methods (labor intensive) and indirect–based methods. LAI defined as one half of the total green leaf area per unit surface is a primary control on the exchange of energy and mass exchanges between the atmosphere and terrestrial ecosystems.Classification of forest point cloud data (PCD) generated from LiDAR into photosynthetic canopy components, non–photosynthetic canopy components and bare earth allowing the determination of woody–to–total area ratio (WTA) with the ultimate goal of obtaining accurate estimates of LAI. Our proposed solution includes engineering new features from existent ones, the use of geometrical properties of the PCD at different scales (intrinsic dimension), possible non–linear dimensionality reduction (auto–encoders), linear dimensionality reduction (PCA) and finally the use of a feed–forward neural network classifier. We would also like to include experiments with ensemble methods and random forest classifiers. Automatic classification of the forest point cloud data set will facilitate the application of TLS on retrieving 3D forest canopy structural parameters, including LAI and leaf and woody area ratios.</p>
			
					
					
					

					<!-- <a href="#" class="image fit"><img src="images/pic01.jpg" alt="" /></a>-->
					
					<p><span class="image left"><img src="images/burning-ice.jpg" alt="" /></span><h4>The evolution of Methane Hydrates.</h4> We have considered a 
					simplified model for evolution of methane hydrates in the hydrate zone, which includes a parameter-dependent
					maximum solubility constraint represented as a nonlinear complementarity constraint (for solubility).
					Our model consists of a single PDE and two unknowns (solubility and saturation), which are bounded by 
					a parameter dependent family of graphs. We have already analyzed solvability and other properties of 
					the fully discrete scheme for the model.</p>
					
					<p><span class="image right"><img src="images/AdsorptionProcPoster.png" alt="" /></span><h4>Systems of conservation laws for thermodynamically consistent 
					adsorption with subscale diffusion and memory terms.</h4>
					Multicomponent adsorption is typically described by a system of conservation laws in which the nonlinear flux terms come
					from explicit functional relationships called isotherms. The most popular extended Langmuir isotherm is thermodynamically 
					inconsistent. We discuss analysis and numerical approximation of a multicomponent adsorption system where the thermodynamically
					consistent isotherms are given only implicitly, or from a coupled microscopic model. I am currently developing more examples and 
					analyzing the stability of the system scheme.</p>
					
					
					
					
				</div>
			</section>
			
		

		<!-- Footer -->
			

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>